{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divassya/BigDataAnalysis/blob/main/Colab_Spark_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmxLySb20jtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1513e2-959d-4f32-dea4-0e345a5f58c9"
      },
      "source": [
        "# Spark installation on Colab\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# !wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "# !tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "# !pip install -q findspark\n",
        "# !rm -rf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!pip install --ignore-installed -q pyspark==3.1.2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 62 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nor9olN20p0M"
      },
      "source": [
        "# Set JAVA_HOME and SPARK_HOME\n",
        "import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"spark-3.0.1-bin-hadoop3.2\"\n",
        "\n",
        "# import findspark\n",
        "# findspark.init(\"spark-3.0.1-bin-hadoop3.2\")# SPARK_HOME\n",
        "\n",
        "\n",
        "import sys\n",
        "import requests\n",
        "from operator import add\n",
        "\n",
        "from pyspark import SparkConf,SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as func\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = SparkContext.getOrCreate()\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY060QsjT8Wr"
      },
      "source": [
        "ls -lah"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYvYeA5RUImn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22a0ffe-a333-4834-f564-0973c93111f8"
      },
      "source": [
        "ls -la sample_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 55512\n",
            "drwxr-xr-x 1 root root     4096 Sep 14 13:44 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root     4096 Sep 14 13:44 \u001b[01;34m..\u001b[0m/\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 \u001b[01;32manscombe.json\u001b[0m*\n",
            "-rw-r--r-- 1 root root   301141 Sep 14 13:44 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Sep 14 13:44 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Sep 14 13:44 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Sep 14 13:44 mnist_train_small.csv\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 \u001b[01;32mREADME.md\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL3CjM3406y4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsNqWX8hUbeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6193b604-2e01-486f-ad2f-10befa9ca40c"
      },
      "source": [
        "rdd1 = sc.parallelize(range(1, 10))\n",
        "rdd1.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCw_vFd7YF2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d251be3f-3d08-4844-e1ac-b3df4ebedd6b"
      },
      "source": [
        "californiaHousing = sc.textFile(\"./sample_data/california_housing_test.csv\")\n",
        "californiaHousing.take(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"',\n",
              " '-122.050000,37.370000,27.000000,3885.000000,661.000000,1537.000000,606.000000,6.608500,344700.000000']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bNmkjaMYk7r"
      },
      "source": [
        "data = [(0,'James','Smith','CS767',93),\n",
        "  (1,'Michael','Rose','MA582',85),\n",
        "  (2,'Robert','Williams','CS767',90),\n",
        "  (3,'Maria','Jones','CS777',75),\n",
        "  (4,'Jen','Brown','CS779',80),\n",
        "  (0,'James','Smith','CS555',80),\n",
        "  (1,'Michael','Rose','CS555',100)\n",
        "]\n",
        "\n",
        "columns = ['id',\"firstname\",\"lastname\",\"coursenumber\",\"grade\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ooUCUtF_jzF",
        "outputId": "27425f10-e7c6-4db1-c56e-45cf9a7ea0da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------+------------+-----+\n",
            "| id|firstname|lastname|coursenumber|grade|\n",
            "+---+---------+--------+------------+-----+\n",
            "|  0|    James|   Smith|       CS767|   93|\n",
            "|  1|  Michael|    Rose|       MA582|   85|\n",
            "|  2|   Robert|Williams|       CS767|   90|\n",
            "|  3|    Maria|   Jones|       CS777|   75|\n",
            "|  4|      Jen|   Brown|       CS779|   80|\n",
            "|  0|    James|   Smith|       CS555|   80|\n",
            "|  1|  Michael|    Rose|       CS555|  100|\n",
            "+---+---------+--------+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhDccYbj_l8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}