{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVBG3cZupkNFiPG9uQtwDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divassya/BigDataAnalysis/blob/main/AssiyaKaratay_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Info \n",
        "Assignment 1\n",
        "MET CS777 Big Data Analytics\n",
        "\n",
        "Faculty - Farshid Alizadeh-Shabdiz, PhD, MBA\n",
        "\n",
        "Student - Assiya Karatay U95161396 karatay@bu.edu 857-294-7028"
      ],
      "metadata": {
        "id": "ODt_yiGpdNsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import libraries"
      ],
      "metadata": {
        "id": "aIDIYb9qdfhu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv4gRN_S8hU1",
        "outputId": "a1cfdd6b-eb52-41b0-acb7-03d9d461ea45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 94 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 74.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Spark installation on Colab\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# !wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "# !tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "# !pip install -q findspark\n",
        "# !rm -rf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!pip install --ignore-installed -q pyspark==3.1.2 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set JAVA_HOME and SPARK_HOME\n",
        "import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"spark-3.0.1-bin-hadoop3.2\"\n",
        "\n",
        "# import findspark\n",
        "# findspark.init(\"spark-3.0.1-bin-hadoop3.2\")# SPARK_HOME\n",
        "\n",
        "\n",
        "import sys\n",
        "import requests\n",
        "from operator import add\n",
        "\n",
        "from pyspark import SparkConf,SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "EBfUv_Kr8iBm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get the data"
      ],
      "metadata": {
        "id": "lgifdKo4djgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data\n",
        "path = \"./\"\n",
        "filename = \"taxi-data-sorted-small.csv.bz2\"\n",
        "# filename = sys.argv[1]\n",
        "lines = sc.textFile(filename)\n",
        "taxilines = lines.map(lambda x: x.split(','))"
      ],
      "metadata": {
        "id": "5Yxrb27v8kvB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### data processing"
      ],
      "metadata": {
        "id": "RftoiMT_dosI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exception handling and removing wrong data lines\n",
        "def isfloat(value):\n",
        "  try:\n",
        "    float(value)\n",
        "    return True\n",
        "  except:\n",
        "    return False\n",
        "\n",
        "# remove lines if they do not have 17 values\n",
        "def correctRows(p):\n",
        "  if (len(p) == 17):\n",
        "    if (isfloat(p[5]) and isfloat(p[11])):\n",
        "      if (float(p[5])!=0 and float(p[11])!=0):\n",
        "        return p\n",
        "\n",
        "#cleaning up data\n",
        "taxilinesCorrected = taxilines.filter(correctRows)"
      ],
      "metadata": {
        "id": "mvNVHR6H8-qQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 1 - Top-10 Active Taxis (25 points) "
      ],
      "metadata": {
        "id": "kc0AXxI5dxsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the top ten taxis that have had the largest number of drivers. \n",
        "# p[0] is the medallion of the taxi and p[1] is the hack license of the driver\n",
        "\n",
        "# 1. get a pair of distinct medallions and drivers\n",
        "TaxiDriver = taxilinesCorrected.map(lambda p: (p[0], p[1]))\n",
        "distinctTaxiDriver = TaxiDriver.distinct()\n",
        "# 2. count number of drivers for each taxi \n",
        "countDriversPerTaxi = distinctTaxiDriver.map(lambda p: (p[0], 1)).reduceByKey(lambda a,b: a+b)\n",
        "# 3. Get the answer in a pair of the medallion and the number of drivers) \n",
        "top10Taxis = sc.parallelize(countDriversPerTaxi.top(10, lambda x:x[1]))\n",
        "# 4. Save it to text file\n",
        "output_file = 'ActiveTaxis'\n",
        "# output_file = sys.argv[2]\n",
        "top10Taxis.saveAsTextFile(output_file)\n",
        "\n",
        "# sc.stop()  "
      ],
      "metadata": {
        "id": "B4uBJhrA-mPe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2 - Top-10 Best Drivers (35 Points) "
      ],
      "metadata": {
        "id": "76eegSPveZFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Map hack licenses,trip time in minutes and total amount of revenue  \n",
        "minsAndRevenue = taxilinesCorrected.map(lambda p: (p[1], (float(p[4])/60, float(p[16]))))\n",
        "# 2. Sum minutes and revenues per hack license\n",
        "sumOfMinsAndRevenue = minsAndRevenue.reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1]))\n",
        "# 3. Filter out trips that have less than 1 minute and 0 revenue\n",
        "zerosRemoved = sumOfMinsAndRevenue.filter(lambda x:x[1][0] >= 1 and x[1][1] != 0)\n",
        "# 4. Divide the total revenue by total minutes for each hack license\n",
        "moneyPerMinute = zerosRemoved.map(lambda a: (a[0], a[1][1]/a[1][0]))\n",
        "# 5. Get top 10 drivers with their revenue per minute) \n",
        "top10Drivers = sc.parallelize(moneyPerMinute.top(10, lambda x:x[1]))\n",
        "# 6. Save it to text file\n",
        "# top10drivers.saveAsTextFile(sys.argv[2])\n",
        "top10Drivers.saveAsTextFile(\"bestDrivers1\")\n",
        "\n",
        "# sc.stop() "
      ],
      "metadata": {
        "id": "5EFP8b-ACWUe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 3 - Best time of the day to Work on Taxi (40 Points) "
      ],
      "metadata": {
        "id": "gSGUjb4tk691"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Map pickup time, miles and surcharge amount \n",
        "hourSurchargeMiles = taxilinesCorrected.map(lambda p: (p[2].split(' ')[1].split(':')[0], (float(p[5]), float(p[12]))))\n",
        "# 2. Remove the trips with 0 miles and surcharge\n",
        "zerosRemoved = hourSurchargeMiles.filter(lambda x: x[1][0] != 0 and x[1][1] != 0)\n",
        "# 3. Sum surcharge amount and miles per hour\n",
        "totalSurchargeAndMiles = zerosRemoved.reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1]))\n",
        "# 4. Divide total surcharge amount by total miles for each hour\n",
        "profitRatio = totalSurchargeAndMiles.map(lambda a: (a[0], a[1][1]/a[1][0]))\n",
        "# 5. Get the highest ratio as (hour, profitRatio) \n",
        "highestRate = sc.parallelize(profitRatio.top(1, lambda x:x[1]))\n",
        "# 6. Save the answer to text file\n",
        "# highestRate.saveAsTextFile(sys.argv[2])\n",
        "highestRate.saveAsTextFile(\"bestTaxiTime1\")\n",
        "\n",
        "\n",
        "sc.stop() "
      ],
      "metadata": {
        "id": "tKn0gdmtlDqy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 4 – Advanced question (10 points)\n",
        "Here are two further tasks for advanced groups. \n",
        "•\tWhat percentage of taxi customers pay with cash and what percentage use electronic cards? Analyze these payment methods for different time of the day and provide a list of percentages for each hour of the day? As a result provide two numbers for total percentages and a list like (hour of the day, percent paid card) "
      ],
      "metadata": {
        "id": "gpNipA6oQAk0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFBRmWiLMX0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEh0fG_Evhxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckDySneHvh00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYyqSRhrvh5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HnF_dYTvh9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "•\tWe would like to measure the efficiency of taxis drivers by finding out their average earned money per mile. (Consider the total amount which includes tips, as their earned money) Implement a Spark job that can find out the top-10 efficient taxi divers. \n",
        "#### Task 4 – More Advanced questions for interested students – needs research (No Grade)\n",
        "•\tWhat are mean, median, first and third quantiles of tip amount? How do find the median? \n",
        "•\tUsing the IQR outlier detection method find out the top-10 outliers. \n"
      ],
      "metadata": {
        "id": "5fzA432GviTs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4l_LdPokvlWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}